{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport importlib\n#from paths_creating_and_images_copying import * ## once you have previous script downloaded, no path are needed below\nimport numpy as np\nfrom datetime import datetime\nimport json\nimport keras\nfrom keras import layers\nfrom keras import models\nfrom keras import Model\nfrom tensorflow.keras import optimizers\nfrom keras.models import load_model\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import callbacks\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport random\nimport cv2 as cv\n## paths\n\nmodel_dir = '/kaggle/input/disaster-images-dataset-cnn-model/DisasterModel'\n\ncyclone_dir = r'/kaggle/input/disaster-images-dataset-cnn-model/DisasterModel/cyclone'\nearthquake_dir = r'/kaggle/input/disaster-images-dataset-cnn-model/DisasterModel/earthquake'\nflood_dir = r'/kaggle/input/disaster-images-dataset-cnn-model/DisasterModel/flood'\nwildfire_dir = r'/kaggle/input/disaster-images-dataset-cnn-model/DisasterModel/wildfire'\n\ntrain_dir = os.path.join(model_dir, 'train')\nvalidation_dir = os.path.join(model_dir, 'validation')\ntest_dir = os.path.join(model_dir, 'test')\n\ntrain_dir_c = os.path.join(train_dir, 'cyclone')\ntrain_dir_e = os.path.join(train_dir, 'earthquake')\ntrain_dir_f = os.path.join(train_dir, 'flood')\ntrain_dir_w = os.path.join(train_dir, 'wildfire')\n\nvalidation_dir_c = os.path.join(validation_dir, 'cyclone')\nvalidation_dir_e = os.path.join(validation_dir, 'earthquake')\nvalidation_dir_f = os.path.join(validation_dir, 'flood')\nvalidation_dir_w = os.path.join(validation_dir, 'wildfire')\n\ntest_dir_c = os.path.join(test_dir, 'cyclone')\ntest_dir_e = os.path.join(test_dir, 'earthquake')\ntest_dir_f = os.path.join(test_dir, 'flood')\ntest_dir_w = os.path.join(test_dir, 'wildfire')\n\nprint('Check if samples are of same size:\\n\\nTrain:')\nprint(len(os.listdir(train_dir_c)), len(os.listdir(train_dir_e)), len(os.listdir(train_dir_f)), len(os.listdir(train_dir_w)))\nprint('Validation:')\nprint(len(os.listdir(validation_dir_c)), len(os.listdir(validation_dir_e)), len(os.listdir(validation_dir_f)), len(os.listdir(validation_dir_w)))\nprint('Test:')\nprint(len(os.listdir(test_dir_c)), len(os.listdir(test_dir_e)), len(os.listdir(test_dir_f)), len(os.listdir(test_dir_w)))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-07T13:50:18.067413Z","iopub.execute_input":"2021-12-07T13:50:18.067941Z","iopub.status.idle":"2021-12-07T13:50:18.099222Z","shell.execute_reply.started":"2021-12-07T13:50:18.067904Z","shell.execute_reply":"2021-12-07T13:50:18.098492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denseblock(input):\n    aux = input\n    for i in range(6): \n        batch_norm = layers.BatchNormalization()(aux)\n        relu = layers.Activation('relu')(batch_norm)\n        conv = layers.Conv2D(26, (3,3) ,padding='same')(relu)\n        conv = layers.Dropout(0.2)(conv)\n        concat = layers.Concatenate(axis=-1)([aux, conv])\n        aux = concat\n    return aux\n\ndef transition(input):\n    batch_norm = layers.BatchNormalization()(input)\n    relu = layers.Activation('relu')(batch_norm)\n    bottle_neck = layers.Conv2D(26, (1,1), padding='same')(relu)\n    dropout = layers.Dropout(0.2)(bottle_neck)\n    pooling = layers.AveragePooling2D(pool_size=(2,2))(dropout)\n    return pooling\n\ndef output_layer(input):\n    batch_norm = layers.BatchNormalization()(input)\n    relu = layers.Activation('relu')(batch_norm)\n    pooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n    x = layers.Flatten()(pooling)\n    x = layers.Dense(200)(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(4)(x)\n    \n    output = layers.Activation('softmax')(x)\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:50:18.21175Z","iopub.execute_input":"2021-12-07T13:50:18.212121Z","iopub.status.idle":"2021-12-07T13:50:18.221645Z","shell.execute_reply.started":"2021-12-07T13:50:18.212089Z","shell.execute_reply":"2021-12-07T13:50:18.220684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input = layers.Input(shape=(180, 180, 3,))\nconv1 = layers.Conv2D(64, (5,5) ,padding='same')(input)\n\ndense_block1 = denseblock(conv1)\ntrans1 = transition(dense_block1)\n\ndense_block2 = denseblock(trans1)\ntrans2 = transition(dense_block2)\n\ndense_block3 = denseblock(trans2)\ntrans3 = transition(dense_block3)\n\ndense_block4 = denseblock(trans3)\noutput = output_layer(dense_block4)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:50:18.396495Z","iopub.execute_input":"2021-12-07T13:50:18.396722Z","iopub.status.idle":"2021-12-07T13:50:18.953894Z","shell.execute_reply.started":"2021-12-07T13:50:18.396694Z","shell.execute_reply":"2021-12-07T13:50:18.953191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = None\n\nmodel_path = '/kaggle/input/disaster-images-dataset-cnn-model/best_model.h5'\nmodel_history_path = '/kaggle/input/disaster-images-dataset-cnn-model/history'\n\nmodel_exists = os.path.exists(model_path)\nmodel_exists = False\n\nhistory_exists = os.path.exists(model_history_path)\nhistory_exists = False\n\nif model_exists:\n    model = load_model(model_path)\n\nelse:\n    model = Model(inputs=[input], outputs=[output])\n\n#keras.backend.clear_session()\nmodel.summary()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:50:18.95586Z","iopub.execute_input":"2021-12-07T13:50:18.95621Z","iopub.status.idle":"2021-12-07T13:50:19.039155Z","shell.execute_reply.started":"2021-12-07T13:50:18.956173Z","shell.execute_reply":"2021-12-07T13:50:19.038481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not model_exists:\n    model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])\n\n\ntrain_datagen = ImageDataGenerator(rescale= 1./255,\n                                    rotation_range= 40,\n                                    width_shift_range= .2,\n                                    height_shift_range= .2,\n                                    shear_range= .2,\n                                    zoom_range= .2,\n                                    horizontal_flip= True)\n\ntest_datagen = ImageDataGenerator(rescale= 1./255)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    target_size= (180, 180),\n                                                    batch_size=32,\n                                                    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(validation_dir,\n                                                    target_size=(180, 180),\n                                                    batch_size=32,\n                                                    class_mode='categorical')\n\nprint('\\n\\nCheck a size of data/label batches:')\nfor data_batch, label_batch in train_generator:\n    print('data batch size:', data_batch.shape)\n    print('label batch size:', label_batch.shape)\n    break\n\n# logdir = \"C:\\\\Users\\\\Miko≈Çaj\\\\Desktop\\\\python\\\\MachineLearning\\\\KERAS\\\\DisasterModel\\\\Logs\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n# tensorboard_callback = keras.callbacks.TensorBoard(log_dir = logdir, histogram_freq=0, write_graph=True, write_images=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:50:19.040486Z","iopub.execute_input":"2021-12-07T13:50:19.040736Z","iopub.status.idle":"2021-12-07T13:50:20.340416Z","shell.execute_reply.started":"2021-12-07T13:50:19.040704Z","shell.execute_reply":"2021-12-07T13:50:20.339657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=6)\nmc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n\nhistory = None\n\n\nhistory = model.fit_generator(train_generator,\n#                               steps_per_epoch=150, \n                              epochs=100, \n                              validation_data=validation_generator, \n#                               validation_steps=50, \n                              callbacks=[mc]\n                             ) ##in callback one can put tensorboard_callback once lines 114 and 117 are run\n\n    \n## with open(model_history_path, 'w') as json_file:\n##     json.dump(str(history.history), json_file)\n# Once the model is trained, we can evaluate and test it. In the below we take 400 images from the test directory, evaluate the model and list accuracy score and loss value, also there is a function which plots 9 images, named by model's predictions.\n\nmodel_dir = '/kaggle/input/disaster-images-dataset-cnn-model/DisasterModel'\ntest_dir = os.path.join(model_dir, 'test')\n\n# best_model = '/kaggle/input/disaster-images-dataset-cnn-model/best_model.h5'\n\nlabel_names = {0: 'cyclone', 1: 'earthquake', 2: 'flood', 3: 'wildfire'}\n\n# model = load_model(best_model)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:50:20.342161Z","iopub.execute_input":"2021-12-07T13:50:20.342519Z","iopub.status.idle":"2021-12-07T15:48:50.813567Z","shell.execute_reply.started":"2021-12-07T13:50:20.342477Z","shell.execute_reply":"2021-12-07T15:48:50.812839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model(\"best_model.h5\")\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(validation_dir, target_size=(180, 180), batch_size=1)\n\nprint(len(test_generator)) # [] batch_nr, [] data/labels, [] img_nr, [][] dims, [] channels\n\nloss_test, acc_test = model.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:42:51.01731Z","iopub.execute_input":"2021-12-07T13:42:51.01757Z","iopub.status.idle":"2021-12-07T13:43:03.269725Z","shell.execute_reply.started":"2021-12-07T13:42:51.017538Z","shell.execute_reply":"2021-12-07T13:43:03.269031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# The accuracy of the model is: 0.84 % for loss value 0.06 %.\n# def run_prediction():\n#     n = 331\n#     plt.figure(figsize=(15, 15))\n#     for i in range(9):\n#         plt.subplot(n)\n#         idx = random.randint(0, len(test_generator)-1)\n#         predict = model.predict(test_generator[idx][0])\n#         plt.imshow(test_generator[idx][0][0])\n#         plt.title(label_names[np.argmax(predict)])\n#         n += 1\n# run_prediction()\n\n# Sometime it might be useful to have a look, what's going on inside our model. For convolutional neural networks we can take a look on particular layers (for example to see what patterns are recognized in each one). In the below, we take a random image, plot it with predicted name, then present what the model sees during 'recognition' on particular level.\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:12:29.677462Z","iopub.status.idle":"2021-12-07T13:12:29.677856Z","shell.execute_reply.started":"2021-12-07T13:12:29.677687Z","shell.execute_reply":"2021-12-07T13:12:29.677705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_model = '/kaggle/input/disaster-images-dataset-cnn-model/best_model.h5'\n# model = load_model(best_model)\n\n# sample_datagen = ImageDataGenerator(rescale = 1./255)\n# sample_dir = r'/kaggle/input/disaster-images-dataset-cnn-model/DisasterModel'\n\n# sample_generator = sample_datagen.flow_from_directory(sample_dir, target_size=(180, 180), batch_size=1)\n\n# def run_visualisation():\n\n#     i = random.randint(0, len(sample_generator) - 1)\n\n#     plt.figure(figsize=(10, 10))\n#     predict = model.predict(sample_generator[i][0])\n#     title ='The below image should present the ' + str(label_names[np.argmax(predict)]) +'\\n'\n#     plt.title(title, fontsize=20)\n#     plt.imshow(sample_generator[i][0][0])\n#     plt.show()\n\n\n#     layer_outputs = [layer.output for layer in model.layers]\n#     activation_model = Model(inputs=model.input, outputs=layer_outputs)\n#     activations = activation_model.predict(sample_generator[i][0])\n\n#     def display_activation(activations, col_size, row_size, act_index):\n#         activation = activations[act_index]\n#         activation_index=0\n#         fig, ax = plt.subplots(row_size, col_size, figsize=(15, 15))\n#         title1 = 'Images from the layer ' + str(act_index)\n#         fig.suptitle(title1, fontsize=16)\n#         for row in range(0, row_size):\n#             for col in range(0, col_size):\n#                 ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n#                 activation_index += 1\n\n#     display_activation(activations, 2, 2, 0) ## 4 images from the 1st layer\n#     plt.show()\n\n#     display_activation(activations, 2, 2, 1) ## 4 images from the 2nd layer\n#     plt.show()\n\n#     display_activation(activations, 2, 2, 3) ## 4 images from the 4th layer\n#     plt.show()\n\n#     display_activation(activations, 3, 3, 5) ## 9 images from the 6th layer\n#     plt.show()\n# Found 6828 images belonging to 4 classes.\n# run_visualisation()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:12:29.682115Z","iopub.status.idle":"2021-12-07T13:12:29.682739Z","shell.execute_reply.started":"2021-12-07T13:12:29.68252Z","shell.execute_reply":"2021-12-07T13:12:29.682543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}