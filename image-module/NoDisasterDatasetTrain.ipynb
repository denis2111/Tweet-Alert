{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport importlib\n#from paths_creating_and_images_copying import * ## once you have previous script downloaded, no path are needed below\nimport numpy as np\nfrom datetime import datetime\nimport json\nimport keras\nfrom keras import layers\nfrom keras import models\nfrom keras import Model\nfrom tensorflow.keras import optimizers\nfrom keras.models import load_model\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import callbacks\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.python.keras.preprocessing.image import image_dataset_from_directory\n\nimport matplotlib.pyplot as plt\nimport random\nimport cv2 as cv\n## paths\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-08T04:49:13.787693Z","iopub.execute_input":"2021-12-08T04:49:13.787933Z","iopub.status.idle":"2021-12-08T04:49:18.827968Z","shell.execute_reply.started":"2021-12-08T04:49:13.787855Z","shell.execute_reply":"2021-12-08T04:49:18.827105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageFile\n\ncount = 0\n\nfor root, dirs, files in os.walk(\"../input/disaster-images-dataset\", topdown=False):\n    for name in files:\n            try:\n                img = Image.open(os.path.join(root, name))\n                img.verify()\n            except (IOError, SyntaxError) as e:\n\n                # Count number of corrupt images\n                count = count + 1\n                print('Bad file:', name)\n\n                # Move corrupt images to a different folder on computer\n                # shutil.move(os.path.join(root, name), '../Data/Corrupted_Images')\nprint(f'Number of corrupted images found = {count}')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:49:53.340843Z","iopub.execute_input":"2021-12-08T04:49:53.34151Z","iopub.status.idle":"2021-12-08T04:51:20.88783Z","shell.execute_reply.started":"2021-12-08T04:49:53.341471Z","shell.execute_reply":"2021-12-08T04:51:20.887043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !find 02_0069.png ../Data/Disasters/train/","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:48:41.662952Z","iopub.status.idle":"2021-12-08T04:48:41.6636Z","shell.execute_reply.started":"2021-12-08T04:48:41.663351Z","shell.execute_reply":"2021-12-08T04:48:41.663376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install split-folders\nimport splitfolders \n\nsplitfolders.ratio(\"../input/disaster-images-dataset/Comprehensive Disaster Dataset(CDD)\", output='../Data/Disasters', seed=1337, \n                               ratio=(.8, .2), group_prefix=None) ","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:51:39.318047Z","iopub.execute_input":"2021-12-08T04:51:39.318328Z","iopub.status.idle":"2021-12-08T04:51:48.878321Z","shell.execute_reply.started":"2021-12-08T04:51:39.318297Z","shell.execute_reply":"2021-12-08T04:51:48.877557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm ../Data/Disasters/train/Human_Damage/02_0069.png\nroot = '../Data/Disasters'\n\ntrain_dir = os.path.join(root, 'train')\ntest_dir = os.path.join(root, 'val')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:51:50.768744Z","iopub.execute_input":"2021-12-08T04:51:50.771149Z","iopub.status.idle":"2021-12-08T04:51:51.569548Z","shell.execute_reply.started":"2021-12-08T04:51:50.771103Z","shell.execute_reply":"2021-12-08T04:51:51.568356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denseblock(input):\n    aux = input\n    for i in range(6): \n        batch_norm = layers.BatchNormalization()(aux)\n        relu = layers.Activation('relu')(batch_norm)\n        conv = layers.Conv2D(26, (3,3) ,padding='same')(relu)\n        conv = layers.Dropout(0.2)(conv)\n        concat = layers.Concatenate(axis=-1)([aux, conv])\n        aux = concat\n    return aux\n\ndef transition(input):\n    batch_norm = layers.BatchNormalization()(input)\n    relu = layers.Activation('relu')(batch_norm)\n    bottle_neck = layers.Conv2D(26, (1,1), padding='same')(relu)\n    dropout = layers.Dropout(0.2)(bottle_neck)\n    pooling = layers.AveragePooling2D(pool_size=(2,2))(dropout)\n    return pooling\n\ndef output_layer(input):\n    batch_norm = layers.BatchNormalization()(input)\n    relu = layers.Activation('relu')(batch_norm)\n    pooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n    x = layers.Flatten()(pooling)\n    x = layers.Dense(200)(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(6)(x)\n    \n    output = layers.Activation('softmax')(x)\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:52:52.489005Z","iopub.execute_input":"2021-12-08T04:52:52.489919Z","iopub.status.idle":"2021-12-08T04:52:52.504272Z","shell.execute_reply.started":"2021-12-08T04:52:52.489875Z","shell.execute_reply":"2021-12-08T04:52:52.502962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input = layers.Input(shape=(180, 180, 3,))\nconv1 = layers.Conv2D(64, (5,5) ,padding='same')(input)\n\ndense_block1 = denseblock(conv1)\ntrans1 = transition(dense_block1)\n\ndense_block2 = denseblock(trans1)\ntrans2 = transition(dense_block2)\n\ndense_block3 = denseblock(trans2)\ntrans3 = transition(dense_block3)\n\ndense_block4 = denseblock(trans3)\noutput = output_layer(dense_block4)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:53:03.383906Z","iopub.execute_input":"2021-12-08T04:53:03.384172Z","iopub.status.idle":"2021-12-08T04:53:06.267258Z","shell.execute_reply.started":"2021-12-08T04:53:03.384138Z","shell.execute_reply":"2021-12-08T04:53:06.26653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = None\n\nmodel_path = '/kaggle/input/disaster-images-dataset-cnn-model/best_model.h5'\nmodel_history_path = '/kaggle/input/disaster-images-dataset-cnn-model/history'\n\nmodel_exists = os.path.exists(model_path)\nmodel_exists = False\n\nhistory_exists = os.path.exists(model_history_path)\nhistory_exists = False\n\nif model_exists:\n    model = load_model(model_path)\n\nelse:\n    model = Model(inputs=[input], outputs=[output])\n\n#keras.backend.clear_session()\nmodel.summary()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:53:10.054001Z","iopub.execute_input":"2021-12-08T04:53:10.054428Z","iopub.status.idle":"2021-12-08T04:53:10.149802Z","shell.execute_reply.started":"2021-12-08T04:53:10.054383Z","shell.execute_reply":"2021-12-08T04:53:10.149052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not model_exists:\n    model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])\n\n\ntrain_datagen = ImageDataGenerator(rescale= 1./255,\n                                    rotation_range= 40,\n                                    width_shift_range= .2,\n                                    height_shift_range= .2,\n                                    shear_range= .2,\n                                    zoom_range= .2,\n                                    horizontal_flip= True)\n\ntest_datagen = ImageDataGenerator(rescale= 1./255)\n\ntrain_generator = image_dataset_from_directory(train_dir,\n                                                    image_size= (180, 180),\n                                                    batch_size=32,\n                                                    label_mode ='categorical')\n\nvalidation_generator = image_dataset_from_directory(test_dir,\n                                                    image_size=(180, 180),\n                                                    batch_size=32,\n                                                    label_mode ='categorical')\n\nprint('\\n\\nCheck a size of data/label batches:')\nfor data_batch, label_batch in train_generator:\n    print('data batch size:', data_batch.shape)\n    print('label batch size:', label_batch.shape)\n    break\n\n# logdir = \"C:\\\\Users\\\\Miko≈Çaj\\\\Desktop\\\\python\\\\MachineLearning\\\\KERAS\\\\DisasterModel\\\\Logs\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n# tensorboard_callback = keras.callbacks.TensorBoard(log_dir = logdir, histogram_freq=0, write_graph=True, write_images=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:53:19.799168Z","iopub.execute_input":"2021-12-08T04:53:19.799465Z","iopub.status.idle":"2021-12-08T04:53:22.66823Z","shell.execute_reply.started":"2021-12-08T04:53:19.799433Z","shell.execute_reply":"2021-12-08T04:53:22.667419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# from PIL import Image\n# folder_path = train_dir\n# extensions = []\n# for fldr in os.listdir(folder_path):\n#     sub_folder_path = os.path.join(folder_path, fldr)\n#     for filee in os.listdir(sub_folder_path):\n#         file_path = os.path.join(sub_folder_path, filee)\n#         print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n#         im = Image.open(file_path)\n#         rgb_im = im.convert('RGB')\n#         if filee.split('.')[1] not in extensions:\n#             extensions.append(filee.split('.')[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:29:52.645078Z","iopub.execute_input":"2021-12-07T21:29:52.645335Z","iopub.status.idle":"2021-12-07T21:29:52.650348Z","shell.execute_reply.started":"2021-12-07T21:29:52.6453Z","shell.execute_reply":"2021-12-07T21:29:52.648993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extensions","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:29:52.6515Z","iopub.execute_input":"2021-12-07T21:29:52.651743Z","iopub.status.idle":"2021-12-07T21:29:52.663968Z","shell.execute_reply.started":"2021-12-07T21:29:52.65171Z","shell.execute_reply":"2021-12-07T21:29:52.663116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=6)\nmc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n\nhistory = None\n\n\nhistory = model.fit(train_generator,\n#                               steps_per_epoch=150, \n                              epochs=100, \n                              validation_data=validation_generator, \n#                               validation_steps=50, \n#                               callbacks=[mc]\n                             ) ##in callback one can put tensorboard_callback once lines 114 and 117 are run\n\n    \n## with open(model_history_path, 'w') as json_file:\n##     json.dump(str(history.history), json_file)\n# Once the model is trained, we can evaluate and test it. In the below we take 400 images from the test directory, evaluate the model and list accuracy score and loss value, also there is a function which plots 9 images, named by model's predictions.\n\nmodel_dir = '/kaggle/input/disaster-images-dataset-cnn-model/DisasterModel'\ntest_dir = os.path.join(model_dir, 'test')\n\n# best_model = '/kaggle/input/disaster-images-dataset-cnn-model/best_model.h5'\n\n\n# model = load_model(best_model)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T04:53:30.317689Z","iopub.execute_input":"2021-12-08T04:53:30.318247Z","iopub.status.idle":"2021-12-08T05:44:36.633021Z","shell.execute_reply.started":"2021-12-08T04:53:30.318204Z","shell.execute_reply":"2021-12-08T05:44:36.632265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = load_model(\"best_model.h5\")\n# test_datagen = ImageDataGenerator(rescale=1./255)\n# test_generator = test_datagen.flow_from_directory(test_dir, target_size=(180, 180), batch_size=1)\n\n# print(len(test_generator)) # [] batch_nr, [] data/labels, [] img_nr, [][] dims, [] channels\n\nloss_test, acc_test = model.evaluate(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T05:51:56.125154Z","iopub.execute_input":"2021-12-08T05:51:56.125474Z","iopub.status.idle":"2021-12-08T05:51:58.232935Z","shell.execute_reply.started":"2021-12-08T05:51:56.125437Z","shell.execute_reply":"2021-12-08T05:51:58.232256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:35:34.524632Z","iopub.execute_input":"2021-12-07T21:35:34.525126Z","iopub.status.idle":"2021-12-07T21:35:34.608004Z","shell.execute_reply.started":"2021-12-07T21:35:34.525071Z","shell.execute_reply":"2021-12-07T21:35:34.60727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# The accuracy of the model is: 0.84 % for loss value 0.06 %.\ndef run_prediction():\n    n = 331\n    plt.figure(figsize=(15, 15))\n    for i in range(9):\n        plt.subplot(n)\n        idx = random.randint(0, len(validation_generator)-1)\n        predict = model.predict(validation_generator[idx][0])\n        plt.imshow(validation_generator[idx][0][0])\n        plt.title(label_names[np.argmax(predict)])\n        n += 1\nrun_prediction()\n\n# Sometime it might be useful to have a look, what's going on inside our model. For convolutional neural networks we can take a look on particular layers (for example to see what patterns are recognized in each one). In the below, we take a random image, plot it with predicted name, then present what the model sees during 'recognition' on particular level.\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:36:59.720094Z","iopub.execute_input":"2021-12-07T21:36:59.720803Z","iopub.status.idle":"2021-12-07T21:36:59.934237Z","shell.execute_reply.started":"2021-12-07T21:36:59.720765Z","shell.execute_reply":"2021-12-07T21:36:59.933247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_model = '/kaggle/input/disaster-images-dataset-cnn-model/best_model.h5'\n# model = load_model(best_model)\n\n# sample_datagen = ImageDataGenerator(rescale = 1./255)\n# sample_dir = r'/kaggle/input/disaster-images-dataset-cnn-model/DisasterModel'\n\n# sample_generator = sample_datagen.flow_from_directory(sample_dir, target_size=(180, 180), batch_size=1)\n\n# def run_visualisation():\n\n#     i = random.randint(0, len(sample_generator) - 1)\n\n#     plt.figure(figsize=(10, 10))\n#     predict = model.predict(sample_generator[i][0])\n#     title ='The below image should present the ' + str(label_names[np.argmax(predict)]) +'\\n'\n#     plt.title(title, fontsize=20)\n#     plt.imshow(sample_generator[i][0][0])\n#     plt.show()\n\n\n#     layer_outputs = [layer.output for layer in model.layers]\n#     activation_model = Model(inputs=model.input, outputs=layer_outputs)\n#     activations = activation_model.predict(sample_generator[i][0])\n\n#     def display_activation(activations, col_size, row_size, act_index):\n#         activation = activations[act_index]\n#         activation_index=0\n#         fig, ax = plt.subplots(row_size, col_size, figsize=(15, 15))\n#         title1 = 'Images from the layer ' + str(act_index)\n#         fig.suptitle(title1, fontsize=16)\n#         for row in range(0, row_size):\n#             for col in range(0, col_size):\n#                 ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n#                 activation_index += 1\n\n#     display_activation(activations, 2, 2, 0) ## 4 images from the 1st layer\n#     plt.show()\n\n#     display_activation(activations, 2, 2, 1) ## 4 images from the 2nd layer\n#     plt.show()\n\n#     display_activation(activations, 2, 2, 3) ## 4 images from the 4th layer\n#     plt.show()\n\n#     display_activation(activations, 3, 3, 5) ## 9 images from the 6th layer\n#     plt.show()\n# Found 6828 images belonging to 4 classes.\n# run_visualisation()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T21:33:09.718711Z","iopub.status.idle":"2021-12-07T21:33:09.718987Z","shell.execute_reply.started":"2021-12-07T21:33:09.718846Z","shell.execute_reply":"2021-12-07T21:33:09.718865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"nondisaster.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T05:51:49.072941Z","iopub.execute_input":"2021-12-08T05:51:49.073217Z","iopub.status.idle":"2021-12-08T05:51:49.482485Z","shell.execute_reply.started":"2021-12-08T05:51:49.073186Z","shell.execute_reply":"2021-12-08T05:51:49.481749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['acc'], label='training accuracy')\nplt.plot(history.history['val_acc'], label='test accuracy')\nplt.title('Accuracy during training')\nplt.legend();\nplt.savefig(\"DisasterAccuracy.png\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T05:56:44.044077Z","iopub.execute_input":"2021-12-08T05:56:44.04435Z","iopub.status.idle":"2021-12-08T05:56:44.304895Z","shell.execute_reply.started":"2021-12-08T05:56:44.044318Z","shell.execute_reply":"2021-12-08T05:56:44.304224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history['acc']","metadata":{"execution":{"iopub.status.busy":"2021-12-08T05:54:02.544297Z","iopub.execute_input":"2021-12-08T05:54:02.544999Z","iopub.status.idle":"2021-12-08T05:54:02.550481Z","shell.execute_reply.started":"2021-12-08T05:54:02.544958Z","shell.execute_reply":"2021-12-08T05:54:02.549794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['Drought', 'Earthquake', 'Human', 'Human_Damage', 'Infrastructure', 'Land_Slide', 'Non_Damage_Buildings_Street', 'Non_Damage_Wildlife_Forest', 'Sea', 'Urban_Fire', 'Water_Disaster', 'Wild_Fire']","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:06:05.843839Z","iopub.execute_input":"2021-12-08T06:06:05.844395Z","iopub.status.idle":"2021-12-08T06:06:05.848631Z","shell.execute_reply.started":"2021-12-08T06:06:05.84434Z","shell.execute_reply":"2021-12-08T06:06:05.847864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(validation_generator[0][0])\n# plt.imshow(validation_generator)\nclass_names[np.argmax(predict)]","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:09:05.676575Z","iopub.execute_input":"2021-12-08T06:09:05.676852Z","iopub.status.idle":"2021-12-08T06:09:05.700668Z","shell.execute_reply.started":"2021-12-08T06:09:05.676821Z","shell.execute_reply":"2021-12-08T06:09:05.69876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\\n\\nCheck a size of data/label batches:')\nfor data_batch, label_batch in validation_generator:\n#     print(data_batch[0])\n    predict = model.predict(data_batch[:,0,:])\n    plt.imshow(data_batch[0])\n    class_names[np.argmax(predict)]\n    print('data batch size:', data_batch.shape)\n    print('label batch size:', label_batch.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-12-08T06:10:42.545084Z","iopub.execute_input":"2021-12-08T06:10:42.545354Z","iopub.status.idle":"2021-12-08T06:10:44.033368Z","shell.execute_reply.started":"2021-12-08T06:10:42.545322Z","shell.execute_reply":"2021-12-08T06:10:44.032221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}